---
title: "Creating parser combinators"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating parser combinators}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: parcr.bib
csl: molecular-microbiology.csl
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Goal of the package

The goal of this package is to simplify the creation of parsers for structured
text files generated by instruments. For example, we use the package to 
construct parsers for files generated by 
[plate readers](https://en.wikipedia.org/wiki/Plate_reader). The output of these
instruments is usually text or spreadsheet files. Such files consist of lines of
text organized in higher-order structures like headers with metadata and blocks
of measured values. The parsers generated by this package take a hybrid approach
in parsing: the individual lines are recognized and parsed by using functions 
that use regular expression patterns, like those from the `stringr` package. 
However, the higher-order structures are recognized and parsed by the 
parser combinators from the package. In our experience this approach combines 
the best of two worlds.

## Functional Programming in R

The parsers that you can create with this package make extensive use of
functional programming. Please read about
[Functional Programming](https://adv-r.hadley.nz/fp.html) in R in Hadley 
Wickham's book [**Advanced R**](https://adv-r.hadley.nz).

## Creating parser combinators in R to parse text files

The `parcr` package contains a set of functions that allow you to create simple
parsers with so-called Combinators, Functions that take other functions as 
arguments to create new functions. The philosophy behind the package is 
described in a paper by @Hutton1992. A number of the functions described in 
this paper are implemented with modifications in the current package. 

### The output of the parsers

The parsers constructed with the functions from this package generate a list
as an output. If the parser is successful then the list has an element called
`L` (the *left* part) which contains the output generated by that part of the
character vector which was successfully parsed, and an element `R` ( the 
*right* part) which contains the remainder that was not parsed. When an entire 
character vector is parsed the content of the `R` element equals `character(0)`.
When the parser fails the output will be the empty list `list()`.

### The functions

Please realize that every function described below is a higher order function:
its output is a function. For example, `literal('a')` yields a function. To
use that function you have to provide it with a character vector, the object
that needs to be parsed, as input:

`literal('a') (c('a','att'))`

#### The beginning and the end

```{r setup, echo=FALSE}
library(parcr)
```

- `succeed(o)`: where `o` is any kind of R-object
- `fail()`

The `succeed` and `fail` parsers are the most basic constructors of a parser. 
The `succeed` parser always succeeds, without consuming any input, whereas the
`fail` parser always fails.

The `succeed` parser constructs a `list` object with a 'left' or L-part
that contains the parser result of the consumed part of the input vector and
the 'right' or R-part that contains the unconsumed part of the vector. The
left part can be any R-object.

While `succeed` never fails, `fail` always does, regardless of the input
vector. It returns the empty list `list()` to signal this fact.

In practice, you will not use these two functions to construct parsers. They 
are the cogs of the other functions.

**Examples**

```{r}
succeed("A")("abc")
succeed(data.frame(title="Keisri hull", author="Jaan Kross"))(c("Unconsumed","text"))
```

```{r}
fail()("abc")
```

#### Recognizing an element

The basic functions for recognizing an element in a character vector are

- `literal(c)`: where `c` is a string.
- `satisfy(b)`: where `b()` is a function that takes a string as input and 
                returns `TRUE` or `FALSE`.

**Examples:**

```{r}
literal('abc') (c('abc','def'))
```

```{r}
starts_with_a <- function(x) {grepl("^a", x)}
satisfy(starts_with_a) (c('abc','def'))
```

And here is an example of an unsuccessful parser:

```{r}
literal('a') (c('ab','a'))
```



#### Modifiers of output

The basic functions for modifying output are

- `p %ret% c` : where `p` is a parser and `c` a string
- `p %using% f` : where `p` is a parser and `f()` a function modifying the output of `p`

**Examples:**

```{r}
(literal('a') %ret% "We have an 'a'") (c('a','b'))
```

```{r}
(satisfy(starts_with_a) %using% toupper) (c('abc','d'))
```

#### The basic combinators

- `p1 %or% p2`: where `p1` and `p2` are parsers.
- `p1 %then% p2`: where `p1` and `p2` are parsers.

The `%or%` combinator enables us to try alternative parsers, whereas the 
`%then%` combinator enables us to test sequences of elements in a character
vector.

Note that the result of `%or%` depends on the order of `p1` and `p2`: if both 
would in principle succeed then only the result of `p1` is returned.

**Examples**

```{r}
(literal('A') %or% satisfy(starts_with_a)) (c('abc','def'))
```

```{r}
(literal('A') %then% satisfy(starts_with_a)) (c('A', 'abc'))
```

#### Qantifying combinators

- `zero.or.one(p)`: where `p` is a parser.
- `zero.or.more(p)`: where `p` is a parser.
- `one.or.more(p)`: where `p` is a parser.
- `exactly(n,p)`: where `n` is an integer and `p` is a parser.
- `match.n(n,p)`: where `n` is an integer and `p` is a parser.

`zero.or.one`, `zero.or.more` and `one.or.more` do exactly what their names 
suggest. You should realize that these are greedy parsers: they consume as many
as possible strings that can be successfully parsed by `p`. Similarly, 
`exactly` is a greedy parser, and it fails when there are less or more than `n`
consecutive strings that can be successfully parsed by `p`. On the other hand
`match.n` is not greedy. It consumes `n` but no more strings that can be 
successfully parsed with `p`.

**Examples**

This parser will fail on its input, too many strings starting with "a":
```{r}
zero.or.one(satisfy(starts_with_a)) (c('acc','aat','cgg'))
```


The following is a successful parsing. Note that its result is not merely
`list()`. However it does return an empty list in the `L`-side of the result.
```{r}
zero.or.more(satisfy(starts_with_a)) (c('cat','gac','cct'))
```

```{r}
one.or.more(satisfy(starts_with_a)) (c('att','aac','cct'))
```

```{r}
exactly(2, satisfy(starts_with_a)) (c('att','aac','cct'))
```

```{r}
match.n(1, satisfy(starts_with_a)) (c('att','aac','cct'))
```


## Example: parsing fasta sequence files

As an example of a real application let's try to write a parser for fasta file.

A nucleotide fasta file could look like the example below 

```
>sequence1
TACGTTGTTTTT
CGG

>sequence2
TGGGTTAAATTT
CTTGGCTTTATT
CCGGA
```

Since fasta files are text files we could read such a file using `readLines()`.
Below we simulate the result of reading the file above by constructing a 
character vector called `file` that we will try to parse in this document.

```{r}
file <- c(
  ">sequence1", "TACGTTGTTTTT", "CGG",
  "",
  ">sequence2", "TGGGTTAAATTT", "CTTGGCTTTATT", "CCGGA"
)
```

A faste file consists of one or more sequence blocks, each with a header[^1] 
and a sequence, and each sequence consists of one or more lines of consecutive
symbols without spaces, representing the nucleotides. A sequence block could be
preceded by zero or more empty lines. This description already allows us to 
create a few elements of the `fasta` parser that we want to make:

[^1]: Note that fasta headers can be much more complicated than we pretend here.

```{r}
SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence()
}

Sequence <- function() {
  one.or.more(SequenceLine())
}

Fastafile <- function() {
  one.or.more(SequenceBlock())
}
```

Now we need line-parsers `Header()` and `SequenceLine()` that recognize and 
process these elements in the character vector `file`. We use functions from
`stringr` to do this in a few helper functions.

```{r}
# returns TRUE/FALSE
is.header <- function(line) {
  stringr::str_detect(line, "^>[ \\t]?(\\w+)")
}

# returns the title after the ">"
parse.header <- function(line) {
  stringr::str_match(line, "^>[ \\t]?(\\w+)")
}

# returns TRUE/FALSE
is.sequence.line <- function(line) {
  stringr::str_detect(line, "[GATC]+")
}

# returns the nucleotide string
parse.sequence.line <- function(line) {
  stringr::str_match(line, "([GATC]+)")
}
```

Then we define the parsers.

```{r}
Header <- function() {
  satisfy(is.header) %using% 
    function(line) {
      matches <- parse.header(line)
      return(matches[2])
    }
}

SequenceLine <- function() {
  satisfy(is.sequence.line) %using% 
    function(line) {
      matches <- parse.sequence.line(line)
      return(matches[2])
    }
}
```

Now we use the output

```{r}
Fastafile() (file)
```

The problem with this output is that is not well-structured, and it is difficult
to extract the individual sequences and headers from it. We can structure this 
output by letting every sequence block be returned as an element of a list. We
extend the `SequenceBlock` parser by changing its output with a function using 
the `%using%` operator:

```{r}
SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence() %using%
    function(x) list(x)
}
```

Now the result is a list of two lists, one for each sequence.

```{r}
Fastafile() (file)[["L"]]
```

In principle, this is which looks easier to extract information from, but we can
improve this. First, we want the sequences to appear as one long string, not as
separate character vectors. To attain this goal we extend the `Sequence` parser
by collapsing its output:

```{r}
Sequence <- function() {
  one.or.more(SequenceLine()) %using% 
    function(x) {
      paste(x, collapse="")
    }
}
```

Then we get

```{r}
Fastafile() (file)[["L"]]
```

We know that the first element in each of these lists elements is the header, 
and the second element is the complete sequence. Why not just attach a name 
to each element in these lists? This would make extracting the information even
easier:

```{r}
Header <- function() {
  satisfy(is.header) %using% 
    function(line) {
      matches <- parse.header(line)
      list(header = matches[2])
    }
}

Sequence <- function() {
  one.or.more(SequenceLine()) %using% 
    function(x) {
      list(sequence = paste(x, collapse=""))
    }
}
```

Finally, we have our desired output.

```{r}
d <- Fastafile() (file)[["L"]]
d
```

Let's present the result more concisely:

```{r}
invisible(lapply(d, function(x) {cat(x$header, x$sequence, "\n")}))
```

## Literature
