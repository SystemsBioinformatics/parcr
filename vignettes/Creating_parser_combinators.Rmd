---
title: "Creating parser combinators"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating parser combinators}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: parcr.bib
csl: molecular-microbiology.csl
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Goal of the package

The goal of this package is to simplify the creation of parsers for structured
text files generated by machines like laboratory instruments. For example, we 
use the package to construct parsers for files generated by 
[plate readers](https://en.wikipedia.org/wiki/Plate_reader). The data generated 
by these instruments can usually be exported to text or spreadsheet files. Such
files consist of lines of text organized in higher-order structures like 
headers with metadata and blocks of measured values. It's often convenient to
analyze the data in a program like R. To be able to do that you have to have a
parser that processes these files and creates R-objects as output. The `parcr`
package simplifies the task of creating such parsers.

### Higher order functions in R

The parsers that are created with this package make extensive use of
functional programming. If this topic is new to you then please read about
[Functional Programming](https://adv-r.hadley.nz/fp.html) in R in Hadley 
Wickham's book [**Advanced R**](https://adv-r.hadley.nz).

## Creating parser combinators in R to parse text files

The `parcr` package contains a set of functions that allow you to create simple
parsers with higher order functions, functions that can take functions as input 
and have functions as output. These are sometimes called combinators. The 
ideas behind the package are described in a paper by @Hutton1992. A number of 
the functions described in this paper are implemented with modifications in the
current package. The package was also heavily inspired by the 
[`Ramble`](https://github.com/8bit-pixies/Ramble) package which is written in 
the same vein, but without the explicit parsing of structured text files in
mind.

### The output of the parsers: a `list`

The parsers constructed with the functions from this package generate a `list`
as an output. The parsers read the input vector from left to right.  When the
parser fails the output will be the empty list `list()`. However, if the 
parser is successful then it produces a `list` with two elements. An element 
called `L` (the *left* part) contains the output generated by that part of the
input vector which was successfully parsed, and the element called `R` 
(the *right* part) which contains the remainder that was not parsed. When an
entire  character vector is parsed the content of the `R` element equals 
`character(0)`. The content of the `L` part can be shaped to your desire. This
is demonstrated in the example of the *fasta* file parser later in this 
document.

## A simple example of using parser combinators

Please realize that every function described below is a higher order function:
their output is a function. In its turn, this function can take a character
vector as its input. For example, `literal("a")` yields a function. To
use that function as a parser you have to provide it with a character vector, 
the object that needs to be parsed, as input:

`literal("a")(c("a","att"))`

This parser tests whether the next element in its input is the string "a". It
will succeed in the example above, but will only consume the first element of 
its input and then stop. However, you can also use a higher order function like 
`literal("a")` as input to other higher order functions to create more complex
parsers. For example, the function `then` takes two parsers `p1` and `p2` as 
arguments, `then(p1, p2)` and applies them in sequence to the input. In the
`parcr` package the function is implemented in the infix form `%then%` 
which makes parser constructs better readable. The composite parser:

`literal("a") %then% literal("att")`

looks for an element with string "a" followed by an element with string "att".
Its application to the same vector:

`literal("a") %then% literal("att")(c("a","att"))`

will completely consume the input. In this way, using a number of standard 
parsers defined in the package, you can quickly construct flexible parsers 
taking complex input. Furthermore, the functions also allow you to construct
a desired R object as output while parsing.

## The functions in the `parcr` package

We will now discuss all of the parser combinator functions present in the 
package. You should also study their help pages. In particular the 
**Pseudocode** listed for each of them should help you to understand their
properties.

### The beginning and the end

```{r setup, echo=FALSE}
library(parcr)
```

- `succeed(o)`: where `o` is any kind of R-object
- `fail()`

The `succeed` and `fail` parsers are the nuts and bolts of a parser 
construction. The `succeed` parser always succeeds, without consuming any 
input, whereas the `fail` parser always fails.

The `succeed` parser constructs a `list` object with a 'left' or L-part
that contains the parser result of the consumed part of the input vector and
the 'right' or R-part that contains the unconsumed part of the vector. The
left part can be any R-object.

While `succeed` never fails, `fail` always does, regardless of the input
vector. It returns the empty list `list()` to signal failure.

**Important**: In practice you will probably not not use these two functions to 
construct parsers.

#### Examples

```{r}
succeed("A")("abc")
succeed(data.frame(title="Keisri hull", author="Jaan Kross"))(c("Unconsumed","text"))
```

```{r}
fail()("abc")
```

### Functions for recognizing a string

The basic functions for recognizing an element in a character vector are

- `literal(c)`: where `c` is a string.
- `satisfy(b)`: where `b()` is a logical function: it takes a string as input
                and returns `TRUE` or `FALSE`.
- `eof()`

`eof()` is a special function that detects the end of a character vector, or if 
that character vector contains the lines of text file, the end of the file 
(EOF). In fact, it detects `character(0)` and when successful it turns the 
right hand side of the output into an empty list (`list()`) to signal that 
fact.

#### Examples

```{r}
literal('abc')(c('abc','def'))
```

```{r}
starts_with_a <- function(x) {grepl("^a", x)}
satisfy(starts_with_a)(c('abc','def'))
```

And here is an example of an unsuccessful parser:

```{r}
literal('a')(c('ab','a'))
```

An application of `eof()` to detect that we parsed the input completely.

```{r}
(literal("a") %then% literal("att") %then% eof())(c("a","att"))
```

Notice how this output differs from just

```{r}
(literal("a") %then% literal("att"))(c("a","att"))
```

### Functions that modify the output

The basic functions for modifying output are

- `p %ret% c` : where `p` is a parser and `c` a string
- `p %using% f` : where `p` is a parser and `f()` a function modifying the output of `p`

#### Examples

```{r}
(literal('a') %ret% "We have an 'a'")(c('a','b'))
```

```{r}
(satisfy(starts_with_a) %using% toupper)(c('abc','d'))
```

### The basic combinators

- `p1 %or% p2`: where `p1` and `p2` are parsers.
- `p1 %then% p2`: where `p1` and `p2` are parsers.

The `%or%` combinator enables us to try alternative parsers, whereas the 
`%then%` combinator enables us to test sequences of elements in a character
vector.

Note that the result of `%or%` depends on the order of `p1` and `p2`: if both 
would in principle succeed then only the result of `p1` is returned.

We also have variations of the `%then%` combinator, `%xthen%` and `%thenx%` 
which do test but then discard the result from the first or second argument:

- `p1 %xthen% p2`: where `p1` and `p2` are parsers discards the result from
  `p2`
- `p1 %thenx% p2`: where `p1` and `p2` are parsers discards the result from
  `p1`

#### Examples

```{r}
(literal('A') %or% satisfy(starts_with_a))(c('abc','def'))
```

```{r}
(literal('A') %then% satisfy(starts_with_a))(c('A', 'abc'))
```

```{r}
(literal('>') %thenx% satisfy(starts_with_a))(c('>', 'abc'))
```




### Repeater combinators

- `zero_or_one(p)`: where `p` is a parser.
- `zero_or_more(p)`: where `p` is a parser.
- `one_or_more(p)`: where `p` is a parser.
- `exactly(n,p)`: where `n` is an integer and `p` is a parser.
- `match_n(n,p)`: where `n` is an integer and `p` is a parser.

`zero_or_one`, `zero_or_more` and `one_or_more` do exactly what their names 
suggest. You should realize that these are greedy parsers: they consume as many
as possible strings that can be successfully parsed by `p`. Similarly, 
`exactly` is a greedy parser, and it fails when there are less or more than `n`
consecutive strings that can be successfully parsed by `p`. On the other hand
`match_n` is not greedy. It consumes `n` but no more strings that can be 
successfully parsed with `p`.

#### Examples

This parser will fail on its input, too many strings starting with "a":
```{r}
zero_or_one(satisfy(starts_with_a))(c('acc','aat','cgg'))
```


The following is a successful parse. Note that its result is not merely
`list()` which would have indicated failure, but a two-element left-right list
with an empty list in the left side.
```{r}
zero_or_more(satisfy(starts_with_a))(c('cat','gac','cct'))
```

```{r}
one_or_more(satisfy(starts_with_a))(c('att','aac','cct'))
```

```{r}
exactly(2, satisfy(starts_with_a))(c('att','aac','cct'))
```

```{r}
match_n(1, satisfy(starts_with_a))(c('att','aac','cct'))
```

### Recognizing and processing strings with `match_s`

- `match_s(s)`: where `s` is a function that recognizes and processes strings

When constructing a parser you will often need to recognize as well as process
strings. For example, you want to recognize multiple integers in a line, 
extract these and then return them as a numeric vector. You're not interested
in other elements like comments in these strings. This could be achieved by 
combining `satisfy()` and subsequently `%using%`, like:

`satisfy(has_integers) %using% process_integers`

where `has_integers` is a boolean function and `process_integers` is a function
that both recognizes , extracts and rearranges numbers to a numeric vector. You
will often find that `has_integers` and `process_integers` use the same regular 
expressions. Then it may be more efficient to combine these.

#### Example

```{r}
numbers <- function(x) {
  m <- gregexpr("[[:digit:]]+", x)
  matches <- as.numeric(regmatches(x,m)[[1]])
  if (length(matches)==0) {
    return(list()) # we signal parser failure: no numbers found
  } else {
    return(matches)
  }
}

match_s(numbers)(" 101 12 187 # a comment on these numbers")
```


### Functions that split a string and parse the substrings

- `by_split(p, split, finish = TRUE, fixed = FALSE, perl = FALSE)`: where `p` 
   is a parser
- `by_symbol(p, finish = TRUE)`: where `p` is a parser

Although you can use the string processing functions from the `base` or 
`stringr` packages to parse and process individual elements of a character 
vector it is also possible to parse substrings by first splitting a string.
`by_split` uses a `split` pattern to first split the incoming string and then
applies the parser `p` to it. `by_symbol` splits the incoming string to
individual symbols and then applies the parser `p`. The `finish` boolean
indicates whether the parser should completely consume the split string.

Under the hood these functions use the function `strsplit()` and its `split`,
`fixed` and `perl` arguments are passed on.

#### Examples

```{r}
starts_with_a <- function(x) grepl("^a",x[1])
# don's forget to use satisfy(), it turns starts_with into a parser
by_split(one_or_more(satisfy(starts_with_a)), ",", fixed = TRUE)("atggc,acggg,acttg")
```
```{r}
by_symbol(literal(">") %thenx% one_or_more(literal("b")), finish = FALSE)(">bb")
```

**Note**: Parsers become **slow** when using these two functions extensively.
If that bothers you then you should use the `match_s` or `satisfy()`and 
`%using%` parsers together with string processing functions like `grepl` and 
`grep` or the ones from `stringr` to process strings. Those parsers will be 
much faster.

### Derived functions to recognize empty lines

- `EmptyLine()`
- `Spacer()`
- `MaybeEmpty()`

The function `EmptyLine()` detects and returns empty line. Empty lines are 
either the string `""` or strings consisting entirely of space-like characters
as identified by the regular expression `\\s`. `Spacer()` detects one or more
consecutive empty lines and discards these whereas `MaybeEmpty()` detects zero
or more empty lines and discards these.

#### Examples

```{r}
EmptyLine()("")
```

```{r}
Spacer()(c(" ","\t\t\t", "atgcc"))
```

```{r}
MaybeEmpty()(c("ggacc","gatccg", "atgcc"))
```

## Example application: a parser for *fasta* sequence files

As an example of a somewhat realistic application let's try to write a parser
for fasta-formatted files for nucleotide sequences.

A nucleotide fasta file could look like the example below

```
>sequence1
TACGTTGTTTTT
CGG

>sequence2
TGGGTTAAATTT
CTTGGCTTTATT
CCGGA
```

Since fasta files are text files we could read such a file using `readLines()`.
Below we simulate the result of reading the file above by constructing a 
character vector called `file` that we will try to parse.

```{r}
file <- c(
  ">sequence1", "TACGTTGTTTTT", "CGG",
  "",
  ">sequence2", "TGGGTTAAATTT", "CTTGGCTTTATT", "CCGGA"
)
```

We can distinguish the following higher order components in a fasta file:
 
- A **fasta file**: consists of one or more **sequence blocks** until the 
  **end of the file**.
- A **sequence block**: consist of a **header** and a **sequence**. A 
  sequence block could be preceded by zero or more **empty lines**.
- A **sequence**: consists of one or more **sequence strings**.
- A **header** is a *string* that starts with a ">" immediately followed by
  a **title** without spaces.
- A **sequence string** is a *string* without spaces that consists of one or
  more symbols from the set $\{\text{A},\text{C},\text{G},\text{T}\}$.

This description already suggest which higher order elements of the `fasta` 
parser we need and how they should be constructed[^1]:

[^1]: Note that real fasta headers and sequences can have more complicated
      formats than we pretend here.

```{r}
Fastafile <- function() {
  one_or_more(SequenceBlock()) %then%
    eof()
}

SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence()
}

Sequence <- function() {
  one_or_more(SequenceString())
}

```

Notice that these elements are functions taking no input, hence the empty 
argument brackets `()` behind their names. Now we need to define the 
line-parsers `Header()` and `SequenceString()` that recognize and 
process these elements in the character vector `file`. We use functions from
`stringr` to do this in a few helper functions, and we use `match_s()` to shape
these parsers.

```{r}
# returns the title after the ">" in the sequence header
parse_header <- function(line) {
  # Study stringr::str_match() to understand what we do here
  m <- stringr::str_match(line, "^>(\\w+)")
  if (is.na(m[1])) {
    return(list()) # signal failure: no title found
  } else {
    return(m[2])
  }
}

# returns a sequence string
parse_sequence_line <- function(line) {
  m <- stringr::str_match(line, "([GATC]+)")
  if (is.na(m[1])) {
    return(list()) # signal failure: no nucleotides found
  } else {
    return(m[2])
  }
}
```

Then we define the parsers.

```{r}
Header <- function() {
  match_s(parse_header)
}

SequenceString <- function() {
  match_s(parse_sequence_line)
}
```

Now we have all the elements that we need to apply the `FastaFile()` parser.

```{r}
Fastafile()(file)
```

The problem with this output is that is not well-structured. It just returns 
the elements recognized in each line in an unstructured list object. It is 
difficult to extract the individual sequences and titles from it, we would 
have to write a parser again. So, we should structure the output by letting
every sequence block be returned as an element of a list. To achieve this we 
extend the `SequenceBlock` parser by changing its output with the `%using%` 
operator:

```{r}
SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence() %using%
    function(x) list(x)
}
```

Now the result is a list of two lists, one for each sequence block.

```{r}
Fastafile()(file)[["L"]]
```

In principle, this output is easier to extract information from, but we can
improve it. First, we want the sequences to appear as one long string, not as
separate character vectors corresponding to the lines in the sequence block. 
Therefore, we extend the `Sequence` parser by collapsing its output:

```{r}
Sequence <- function() {
  one_or_more(SequenceString()) %using% 
    function(x) paste(x, collapse="")
}
```

Then we get

```{r}
Fastafile()(file)[["L"]]
```

which looks much better: we know that the first element in each of these lists
is the title and the second element is the complete sequence. Then why not 
just attach a name to these elements? This would make extracting the 
information even easier:

```{r}
Header <- function() {
  match_s(parse_header) %using% 
    function(x) list(title = unlist(x))
}

Sequence <- function() {
  one_or_more(SequenceString()) %using% 
    function(x) list(sequence = paste(x, collapse=""))
}
```

Finally, we have our desired output.

```{r}
d <- Fastafile()(file)[["L"]]
d
```

Let's present the result more concisely using the names of these elements:

```{r}
invisible(lapply(d, function(x) {cat(x$title, x$sequence, "\n")}))
```

## Literature
