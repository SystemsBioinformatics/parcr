---
title: "Creating parser combinators"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating parser combinators}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: parcr.bib
csl: molecular-microbiology.csl
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Goal of the package

The goal of this package is to simplify the creation of parsers for structured
text files generated by instruments. For example, we use the package to 
construct parsers for files generated by 
[plate readers](https://en.wikipedia.org/wiki/Plate_reader). The output of these
instruments is usually text or spreadsheet files. Such files consist of lines of
text organized in higher-order structures like headers with metadata and blocks
of measured values. The parsers generated by this package take a hybrid approach
in parsing: the individual lines are recognized and parsed by using functions 
that use regular expression patterns, like those from the `stringr` package. 
However, the higher-order structures are recognized and parsed by the 
parser combinators from the package. In our experience this approach combines 
the best of two worlds.

## Functional Programming in R

The parsers that you can create with this package make extensive use of
functional programming. If this topic is new to you then please read about
[Functional Programming](https://adv-r.hadley.nz/fp.html) in R in Hadley 
Wickham's book [**Advanced R**](https://adv-r.hadley.nz).

## Creating parser combinators in R to parse text files

The `parcr` package contains a set of functions that allow you to create simple
parsers with so-called Combinators, Functions that take other functions as 
arguments to create new functions. The philosophy behind the package is 
described in a paper by @Hutton1992. A number of the functions described in 
this paper are implemented with modifications in the current package. 

### The output of the parsers

The parsers constructed with the functions from this package generate a list
as an output. The parsers read the input vector from left to right. If the 
parser is successful then the list has an element called `L` (the *left* part)
which contains the output generated by that part of the character vector which
was successfully parsed, and an element `R` (the *right* part) which contains
the remainder that was not parsed. When an entire  character vector is parsed
the content of the `R` element equals `character(0)`.When the parser fails
the output will be the empty list `list()`.

## The parsers

Please realize that every function described below is a higher order function:
their output is a function. In its turn, this function can take a character
vector as its input. For example, `literal('a')` yields a function. To
use that function as a parser you have to provide it with a character vector, 
the object that needs to be parsed, as input:

`literal('a')(c('a','att'))`

However, you can also use these higher order functions as input to other higher
order functions to create more complex parsers. For example, the function 
`%then%` takes two parsers as arguments and is defined as an infix function. 
The composite parser:

`literal('a') %then% literal('att')`

looks for an 'a' followed by a 'att' and would completely parse `c('a','att')`. 

In this way, using a number of standard parsers defined in the package, you 
can quickly construct flexible parsers taking complex input, and yielding a
desired output when parsing is successful.

We will now discuss each of these functions present in the package. You should
also study their help pages. In particular the Pseudocode listed for each
of them may help you to understand theur properties.

### The functions for the beginning and the end

```{r setup, echo=FALSE}
library(parcr)
```

- `succeed(o)`: where `o` is any kind of R-object
- `fail()`

The `succeed` and `fail` parsers are the most basic constructors of a parser. 
The `succeed` parser always succeeds, without consuming any input, whereas the
`fail` parser always fails.

The `succeed` parser constructs a `list` object with a 'left' or L-part
that contains the parser result of the consumed part of the input vector and
the 'right' or R-part that contains the unconsumed part of the vector. The
left part can be any R-object.

While `succeed` never fails, `fail` always does, regardless of the input
vector. It returns the empty list `list()` to signal this fact.

**Important**: In practice you will probably not not use these two functions to 
construct parsers. They are components of the basic functions described below.

#### Examples

```{r}
succeed("A")("abc")
succeed(data.frame(title="Keisri hull", author="Jaan Kross"))(c("Unconsumed","text"))
```

```{r}
fail()("abc")
```

### Functions for recognizing a string

The basic functions for recognizing an element in a character vector are

- `literal(c)`: where `c` is a string.
- `satisfy(b)`: where `b()` is a function that takes a string as input and 
                returns `TRUE` or `FALSE`.

#### Examples

```{r}
literal('abc')(c('abc','def'))
```

```{r}
starts_with_a <- function(x) {grepl("^a", x)}
satisfy(starts_with_a)(c('abc','def'))
```

And here is an example of an unsuccessful parser:

```{r}
literal('a')(c('ab','a'))
```



### Functions that modify the output

The basic functions for modifying output are

- `p %ret% c` : where `p` is a parser and `c` a string
- `p %using% f` : where `p` is a parser and `f()` a function modifying the output of `p`

#### Examples

```{r}
(literal('a') %ret% "We have an 'a'")(c('a','b'))
```

```{r}
(satisfy(starts_with_a) %using% toupper)(c('abc','d'))
```

### The basic combinators

- `p1 %or% p2`: where `p1` and `p2` are parsers.
- `p1 %then% p2`: where `p1` and `p2` are parsers.

The `%or%` combinator enables us to try alternative parsers, whereas the 
`%then%` combinator enables us to test sequences of elements in a character
vector.

Note that the result of `%or%` depends on the order of `p1` and `p2`: if both 
would in principle succeed then only the result of `p1` is returned.

#### Examples

```{r}
(literal('A') %or% satisfy(starts_with_a))(c('abc','def'))
```

```{r}
(literal('A') %then% satisfy(starts_with_a))(c('A', 'abc'))
```

### Qantifying combinators

- `zero_or_one(p)`: where `p` is a parser.
- `zero_or_more(p)`: where `p` is a parser.
- `one_or_more(p)`: where `p` is a parser.
- `exactly(n,p)`: where `n` is an integer and `p` is a parser.
- `match_n(n,p)`: where `n` is an integer and `p` is a parser.

`zero_or_one`, `zero_or_more` and `one_or_more` do exactly what their names 
suggest. You should realize that these are greedy parsers: they consume as many
as possible strings that can be successfully parsed by `p`. Similarly, 
`exactly` is a greedy parser, and it fails when there are less or more than `n`
consecutive strings that can be successfully parsed by `p`. On the other hand
`match_n` is not greedy. It consumes `n` but no more strings that can be 
successfully parsed with `p`.

#### Examples

This parser will fail on its input, too many strings starting with "a":
```{r}
zero_or_one(satisfy(starts_with_a))(c('acc','aat','cgg'))
```


The following is a successful parsing. Note that its result is not merely
`list()`. However it does return an empty list in the `L`-side of the result.
```{r}
zero_or_more(satisfy(starts_with_a))(c('cat','gac','cct'))
```

```{r}
one_or_more(satisfy(starts_with_a))(c('att','aac','cct'))
```

```{r}
exactly(2, satisfy(starts_with_a))(c('att','aac','cct'))
```

```{r}
match_n(1, satisfy(starts_with_a))(c('att','aac','cct'))
```

### Functions that split a string and parse the substrings

- `by_split(p, split, finish = TRUE, fixed = FALSE, perl = FALSE)`: where `p` 
   is a parser
- `by_symbol(p, finish = TRUE)`: where `p` is a parser

Although you can use the string processing functions from the `base` or 
`stringr` packages to parse and process individual elements of a character 
vector it is also possible to parse substrings using the parsers above by first
splitting tan incoming element. `by_split` uses a `split` pattern to first
split the incoming string and then applies the parser `p` to it. `by_symbol`
splits the incoming string to individual symbols and then applies the parser 
`p`. The `finish` boolean indicates whether the parser should completely 
consume the split string.

Under the hood, these functions use the function `strsplit()` and the `split`,
`fixed` and `perl` arguments are passed on to that function.

#### Examples

```{r}
starts_with_a <- function(x) grepl("^a",x[1])
# don's forget to use satisfy(), it turns starts_with into a parser
by_split(one_or_more(satisfy(starts_with_a)), ",", fixed = TRUE)("atggc,acggg,acttg")
```
```{r}
by_symbol(literal(">") %thenx% one_or_more(literal("b")), finish = FALSE)(">bb")
```



**Note**: Parsers become slow when using these two functions extensively. If
that bothers you then you should use the `match_s` or `%using%` parsers together
with string processing functions like `grep` or the ones from `stringr` to 
process strings. They lead to much faster parsers.

### Derived functions to recognize empty lines

- `EmptyLine()`
- `Spacer()`
- `MaybeEmpty()`

The function `EmptyLine()` detects and returns empty line. Empty lines are 
either the string `""` or strings consisting entirely of space-like characters
as identified by the regular expression `\\s`. `Spacer()` detects one or more
consecutive empty lines and discards these whereas `MaybeEmpty()` detects zero
or more empty lines and discards these.

#### Examples

```{r}
EmptyLine()("")
```

```{r}
Spacer()(c(" ","\t\t\t", "atgcc"))
```

```{r}
MaybeEmpty()(c("ggacc","gatccg", "atgcc"))
```

## Example application: a parser for *fasta* sequence files

As an example of a somewhat realistic application let's try to write a parser
for *fasta*-formatted files.

A nucleotide fasta file could look like the example below 

```
>sequence1
TACGTTGTTTTT
CGG

>sequence2
TGGGTTAAATTT
CTTGGCTTTATT
CCGGA
```

Since fasta files are text files we could read such a file using `readLines()`.
Below we simulate the result of reading the file above by constructing a 
character vector called `file` that we will try to parse in this document.

```{r}
file <- c(
  ">sequence1", "TACGTTGTTTTT", "CGG",
  "",
  ">sequence2", "TGGGTTAAATTT", "CTTGGCTTTATT", "CCGGA"
)
```

We can distinguish the following higher order components in a fasta file:
 
- A **fasta file**: consist of one or more **sequence blocks**.
- A **sequence block**: consist of a **header**[^1] and a **sequence**. A 
  sequence block could be preceded by zero or more **empty lines**.
- A **sequence**: consists of one or more **sequence strings** consisting of
  consecutive symbols without spaces, representing the nucleotides.

This description already allows us to create a few elements of the `fasta` 
parser that we want to make:

[^1]: Note that fasta headers can be much more complicated than we pretend here.

```{r}
Fastafile <- function() {
  one_or_more(SequenceBlock())
}

SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence()
}

Sequence <- function() {
  one_or_more(SequenceString())
}

```

Now we need line-parsers `Header()` and `SequenceString()` that recognize and 
process these elements in the character vector `file`. We use functions from
`stringr` to do this in a few helper functions, and we use `match_s()` to shape
these parsers. 

```{r}
# returns the title after the ">" in the sequence header
parse_header <- function(line) {
  if (length(line)==0) {
    # This part is needed to return output when reaching the end of a file
    # See the documentation of match_s
    return(list()) # signal failure
  }
  else {
    # Study stringr::str_match() to understand what we do here
    m <- stringr::str_match(line, "^>[ \\t]?(\\w+)")
    if (is.na(m[1])) {
      return(list()) # signal failure
    } else {
      return(m[2])
    }
  }
}

# returns a nucleotide string consisting of consecutive symbols G, A, T or C
parse_sequence_line <- function(line) {
    if (length(line)==0) {
    return(list())
  }
  else {
    m <- stringr::str_match(line, "([GATC]+)")
    if (is.na(m[1])) {
      return(list())
    } else {
      return(m[2])
    }
  }
}
```

Then we define the parsers.

```{r}
Header <- function() {
  match_s(parse_header)
}

SequenceString <- function() {
  match_s(parse_sequence_line)
}
```

Now we use the output

```{r}
Fastafile()(file)
```

The problem with this output is that is not well-structured, and it is difficult
to extract the individual sequences and headers from it. We can structure this 
output by letting every sequence block be returned as an element of a list. We
extend the `SequenceBlock` parser by changing its output with a function using 
the `%using%` operator:

```{r}
SequenceBlock <- function() {
  MaybeEmpty() %then% 
    Header() %then% 
    Sequence() %using%
    function(x) list(x)
}
```

Now the result is a list of two lists, one for each sequence block.

```{r}
Fastafile()(file)[["L"]]
```

In principle, this output is easier to extract information from, but we can
improve it. First, we want the sequences to appear as one long string, not as
separate character vectors corresponding to the lines in the sequence block. 
To attain this goal we extend the `Sequence` parser by collapsing its output:

```{r}
Sequence <- function() {
  one_or_more(SequenceString()) %using% 
    function(x) {
      paste(x, collapse="")
    }
}
```

Then we get

```{r}
Fastafile()(file)[["L"]]
```

We know that the first element in each of these lists elements is the header, 
and the second element is the complete sequence. Why not just attach a name 
to each element in these lists? This would make extracting the information even
easier:

```{r}
Header <- function() {
  match_s(parse_header) %using% 
    function(x) {
      list(header = unlist(x))
    }
}

Sequence <- function() {
  one_or_more(SequenceString()) %using% 
    function(x) {
      list(sequence = paste(x, collapse=""))
    }
}
```

Note that alternatively we could have modified the `parse_header` and 
`parse_sequence_line` functions to attain the same effect. Finally, we have 
our desired output.

```{r}
d <- Fastafile()(file)[["L"]]
d
```

Let's present the result more concisely using the names of these elements:

```{r}
invisible(lapply(d, function(x) {cat(x$header, x$sequence, "\n")}))
```

## Literature
